{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2393841d",
   "metadata": {},
   "source": [
    "# Update torus_points float.h from CSV\n",
    "This notebook reads `main/plugins/rgb/resources/LED torus points float.csv`, extracts the per-slice XYZ points, and writes an updated header `main/plugins/rgb/resources/torus_points float.h` with the new `TORUS_POINTS_COUNT` and `TORUS_POINTS_PER_SLICE`. It will also create a backup of the existing header before overwriting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30808e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV: LED torus points float.csv\n",
      "Header: torus_points float.h\n"
     ]
    }
   ],
   "source": [
    "# Ensure required packages\n",
    "import sys, subprocess\n",
    "def ensure(pkg, import_name=None):\n",
    "    try:\n",
    "        __import__(import_name or pkg)\n",
    "    except ImportError:\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg])\n",
    "\n",
    "ensure('pandas')\n",
    "ensure('numpy')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Paths (repo-root relative)\n",
    "csv_path = Path('LED torus points float.csv')\n",
    "hdr_path = Path('torus_points float.h')\n",
    "backup_path = hdr_path.with_suffix('.h.bak')\n",
    "\n",
    "print('CSV:', csv_path)\n",
    "print('Header:', hdr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11a905e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slices=64, points_per_slice=241, total_points=15424\n"
     ]
    }
   ],
   "source": [
    "# Read CSV and organize per-slice points\n",
    "df = pd.read_csv(csv_path)\n",
    "cols = list(df.columns)\n",
    "# Expect columns like X0,Y0,Z0,X1,Y1,Z1,...\n",
    "pattern = re.compile(r'^\\s*([XYZxyz])(\\d+)\\s*$')\n",
    "slices = {}\n",
    "for col in cols:\n",
    "    m = pattern.match(col)\n",
    "    if not m:\n",
    "        raise ValueError(f'Unexpected column name: {col}')\n",
    "    axis = m.group(1).upper()\n",
    "    idx = int(m.group(2))\n",
    "    slices.setdefault(idx, {})[axis] = df[col].values\n",
    "\n",
    "n_slices = max(slices.keys()) + 1\n",
    "# build per-slice list of (x,y,z) using rows as point index\n",
    "per_slice_points = []\n",
    "for i in range(n_slices):\n",
    "    axes = slices.get(i)\n",
    "    if axes is None or not all(k in axes for k in ('X','Y','Z')):\n",
    "        raise ValueError(f'Slice {i} missing axis columns')\n",
    "    pts = list(zip(axes['X'].astype(float), axes['Y'].astype(float), axes['Z'].astype(float)))\n",
    "    per_slice_points.append(pts)\n",
    "\n",
    "# Validate counts\n",
    "counts = [len(pts) for pts in per_slice_points]\n",
    "if len(set(counts)) != 1:\n",
    "    raise ValueError(f'Inconsistent points-per-slice: {counts[:8]}...')\n",
    "n_per_slice = counts[0]\n",
    "print(f'slices={n_slices}, points_per_slice={n_per_slice}, total_points={n_slices * n_per_slice}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6cec916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup written to torus_points float.h.bak\n",
      "Wrote header: torus_points float.h\n",
      "New TORUS_POINTS_COUNT = 15424\n",
      "New TORUS_POINTS_PER_SLICE = 241\n"
     ]
    }
   ],
   "source": [
    "# Desired update: set per-slice to 241 (user requested) and rewrite header accordingly.\n",
    "desired_per_slice = 241\n",
    "if n_per_slice != desired_per_slice:\n",
    "    print('WARNING: CSV contains', n_per_slice, 'points per slice, but requested', desired_per_slice)\n",
    "    # We'll still write whatever the CSV contains, but update will reflect actual CSV size unless user overrides.\n",
    "\n",
    "n_per_slice_to_write = n_per_slice  # use actual CSV value\n",
    "total = n_slices * n_per_slice_to_write\n",
    "\n",
    "# Read existing header to capture scale comment if present\n",
    "existing = ''\n",
    "if hdr_path.exists():\n",
    "    existing = hdr_path.read_text(encoding='utf-8')\n",
    "    # try to capture Scale applied line\n",
    "    m = re.search(r'Scale applied:\\s*(.*)', existing)\n",
    "    scale_line = m.group(1).strip() if m else ''\n",
    "else:\n",
    "    scale_line = ''\n",
    "\n",
    "# Build header content\n",
    "def fmt(v):\n",
    "    return f'{v:.6f}f'\n",
    "\n",
    "lines = []\n",
    "lines.append('/* Auto-generated torus point LUT')\n",
    "lines.append(f'   Count: {total}')\n",
    "lines.append(f'   Slices: {n_slices}')\n",
    "lines.append(f'   Points per slice: {n_per_slice_to_write}')\n",
    "if scale_line:\n",
    "    lines.append(f'   Scale applied: {scale_line}')\n",
    "else:\n",
    "    lines.append('   Scale applied: none')\n",
    "lines.append('   Stored as: float (32-bit)')\n",
    "lines.append('*/')\n",
    "lines.append('')\n",
    "lines.append('#ifndef TORUS_POINTS_H')\n",
    "lines.append('#define TORUS_POINTS_H')\n",
    "lines.append('')\n",
    "lines.append('#include <stdint.h>')\n",
    "lines.append('#include <stddef.h>')\n",
    "lines.append('')\n",
    "lines.append(f'#define TORUS_POINTS_COUNT {total}')\n",
    "lines.append(f'#define TORUS_POINTS_SLICES {n_slices}')\n",
    "lines.append(f'#define TORUS_POINTS_PER_SLICE {n_per_slice_to_write}')\n",
    "lines.append('')\n",
    "lines.append(f'static const float TORUS_POINTS[{n_slices}][{n_per_slice_to_write}][3] = {{')\n",
    "\n",
    "# Write slices\n",
    "for si, pts in enumerate(per_slice_points):\n",
    "    lines.append('  {')\n",
    "    for (x,y,z) in pts:\n",
    "        lines.append(f'    {{ {x:.6f}f, {y:.6f}f, {z:.6f}f }},')\n",
    "    lines.append('  },')\n",
    "\n",
    "lines.append('};')\n",
    "lines.append('')\n",
    "lines.append('#endif // TORUS_POINTS_H')\n",
    "\n",
    "header_text = '\\n'.join(lines)\n",
    "# Backup existing header\n",
    "if hdr_path.exists():\n",
    "    shutil.copy2(hdr_path, backup_path)\n",
    "    print('Backup written to', backup_path)\n",
    "# Write new header\n",
    "hdr_path.write_text(header_text, encoding='utf-8')\n",
    "print('Wrote header:', hdr_path)\n",
    "print('New TORUS_POINTS_COUNT =', total)\n",
    "print('New TORUS_POINTS_PER_SLICE =', n_per_slice_to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88aa97b",
   "metadata": {},
   "source": [
    "**Run instructions**: Open this notebook, run every cell. The notebook will back up the existing header to `torus_points float.h.bak` and overwrite `torus_points float.h` with the CSV-derived data. If you want to force 241 points per slice when CSV differs, modify the `n_per_slice_to_write` variable in the cell before writing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
